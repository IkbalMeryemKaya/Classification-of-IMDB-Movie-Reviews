{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ebdadf-2a24-44b4-9ae9-0fbe23e5d406",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "\n",
    "# ====== إعدادات المشروع ======\n",
    "TARGET_TOTAL = 2200            # اجمعي أكثر من 2000 احتياط\n",
    "LOAD_MORE_PER_MOVIE = 120      # زيديها إذا العدد قليل\n",
    "CLICK_SLEEP = 1.2              # احترام الموقع (لا تجعليه 0)\n",
    "MIN_WORDS = 12                 # جودة النص (استبعدي القصير جداً)\n",
    "\n",
    "# قائمة أفلام (بدون Romance) — زيدي/غيري حسب الحاجة\n",
    "movie_ids = [\n",
    "    \"tt0137523\",  # Fight Club\n",
    "    \"tt0111161\",  # Shawshank\n",
    "    \"tt0068646\",  # The Godfather\n",
    "    \"tt0468569\",  # The Dark Knight\n",
    "    \"tt1375666\",  # Inception\n",
    "    \"tt0816692\",  # Interstellar\n",
    "    \"tt0102926\",  # Silence of the Lambs\n",
    "    \"tt0114369\",  # Se7en\n",
    "    \"tt0172495\",  # Gladiator\n",
    "    \"tt0133093\",  # The Matrix\n",
    "    \"tt0167261\",  # LOTR: Return of the King\n",
    "    \"tt0080684\",  # The Empire Strikes Back\n",
    "    \"tt0076759\",  # Star Wars\n",
    "]\n",
    "\n",
    "def label_from_rating(r):\n",
    "    # 3-Classes (يسهّل الوصول لـ 2000)\n",
    "    if r >= 7:\n",
    "        return \"positive\"\n",
    "    elif r <= 4:\n",
    "        return \"negative\"\n",
    "    else:\n",
    "        return \"neutral\"  # 5-6\n",
    "\n",
    "# ====== إعداد Selenium (أسرع + أقل إعلانات) ======\n",
    "opts = Options()\n",
    "# بعد ما تتأكدي كل شيء شغّال، فعّلي headless لتسريع:\n",
    "# opts.add_argument(\"--headless=new\")\n",
    "\n",
    "opts.add_argument(\"--lang=en-US\")\n",
    "opts.add_argument(\"--window-size=1400,900\")\n",
    "opts.add_argument(\"--no-sandbox\")\n",
    "opts.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "# تقليل البطء: إيقاف الصور قدر الإمكان\n",
    "prefs = {\"profile.managed_default_content_settings.images\": 2}\n",
    "opts.add_experimental_option(\"prefs\", prefs)\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=opts)\n",
    "wait = WebDriverWait(driver, 25)\n",
    "\n",
    "all_rows = []\n",
    "\n",
    "def accept_consent_if_present():\n",
    "    # أزرار الموافقة تختلف، نجرب أكثر من نمط\n",
    "    xpaths = [\n",
    "        \"//button[contains(., 'Accept')]\",\n",
    "        \"//button[contains(., 'Accept all')]\",\n",
    "        \"//button[contains(., 'I agree')]\",\n",
    "        \"//button[contains(., 'Agree')]\",\n",
    "    ]\n",
    "    for xp in xpaths:\n",
    "        try:\n",
    "            btn = WebDriverWait(driver, 3).until(EC.element_to_be_clickable((By.XPATH, xp)))\n",
    "            btn.click()\n",
    "            time.sleep(1)\n",
    "            return True\n",
    "        except:\n",
    "            pass\n",
    "    return False\n",
    "\n",
    "def click_load_more(max_clicks):\n",
    "    clicks = 0\n",
    "    for _ in range(max_clicks):\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(0.6)\n",
    "        try:\n",
    "            btn = WebDriverWait(driver, 3).until(\n",
    "                EC.element_to_be_clickable((By.CSS_SELECTOR, \"button.ipc-see-more__button\"))\n",
    "            )\n",
    "            driver.execute_script(\"arguments[0].click();\", btn)\n",
    "            clicks += 1\n",
    "            time.sleep(CLICK_SLEEP)\n",
    "        except:\n",
    "            break\n",
    "    return clicks\n",
    "\n",
    "def parse_reviews_from_html(html, movie_id):\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    # (A) تخطيط قديم: div.review-container\n",
    "    cards = soup.select(\"div.review-container\")\n",
    "    if cards:\n",
    "        for c in cards:\n",
    "            text_tag = c.select_one(\"div.text.show-more__control\")\n",
    "            rating_tag = c.select_one(\"span.rating-other-user-rating span\")\n",
    "            if not text_tag or not rating_tag:\n",
    "                continue\n",
    "            review_text = text_tag.get_text(strip=True)\n",
    "            if len(review_text.split()) < MIN_WORDS:\n",
    "                continue\n",
    "            try:\n",
    "                rating = int(rating_tag.get_text(strip=True))\n",
    "            except:\n",
    "                continue\n",
    "            rows.append((review_text, rating, movie_id))\n",
    "        return rows\n",
    "\n",
    "    # (B) تخطيط جديد: article cards + rating مثل \"8/10\"\n",
    "    # نلتقط أي block يشبه review card ويحتوي rating\n",
    "    articles = soup.select(\"article\")\n",
    "    for a in articles:\n",
    "        block_text = a.get_text(\" \", strip=True)\n",
    "        m = re.search(r\"\\b(\\d{1,2})/10\\b\", block_text)\n",
    "        if not m:\n",
    "            continue\n",
    "        rating = int(m.group(1))\n",
    "\n",
    "        # نحاول أخذ النص من سيلكتورات شائعة، وإلا نأخذ جزء كبير من النص\n",
    "        text = None\n",
    "        for sel in [\n",
    "            '[data-testid=\"review-content\"]',\n",
    "            \"div.ipc-html-content-inner-div\",\n",
    "            \"div.text.show-more__control\",\n",
    "        ]:\n",
    "            t = a.select_one(sel)\n",
    "            if t:\n",
    "                text = t.get_text(\" \", strip=True)\n",
    "                break\n",
    "        if not text:\n",
    "            # fallback: خذي block كله لكن فلترته بالطول\n",
    "            text = block_text\n",
    "\n",
    "        if len(text.split()) < MIN_WORDS:\n",
    "            continue\n",
    "\n",
    "        rows.append((text, rating, movie_id))\n",
    "\n",
    "    return rows\n",
    "\n",
    "try:\n",
    "    for mid in movie_ids:\n",
    "        if len(all_rows) >= TARGET_TOTAL:\n",
    "            break\n",
    "\n",
    "        url = f\"https://www.imdb.com/title/{mid}/reviews\"\n",
    "        driver.get(url)\n",
    "        time.sleep(2.0)\n",
    "        accept_consent_if_present()\n",
    "\n",
    "        # انتظر شيء يدل أن الصفحة وصلت (أي وجود زر load more أو وجود /10 في المصدر)\n",
    "        try:\n",
    "            wait.until(lambda d: (\"ipc-see-more__button\" in d.page_source) or (\"/10\" in d.page_source))\n",
    "        except:\n",
    "            print(mid, \"Page did not load reviews properly (blocked/consent).\")\n",
    "            continue\n",
    "\n",
    "        clicks = click_load_more(LOAD_MORE_PER_MOVIE)\n",
    "\n",
    "        html = driver.page_source\n",
    "        parsed = parse_reviews_from_html(html, mid)\n",
    "\n",
    "        added = 0\n",
    "        for review_text, rating, movie_id in parsed:\n",
    "            label = label_from_rating(rating)\n",
    "            all_rows.append({\n",
    "                \"review_text\": review_text,\n",
    "                \"label\": label,\n",
    "                \"rating\": rating,\n",
    "                \"movie_id\": movie_id\n",
    "            })\n",
    "            added += 1\n",
    "            if len(all_rows) >= TARGET_TOTAL:\n",
    "                break\n",
    "\n",
    "        print(mid, f\"LoadMoreClicks={clicks} ParsedRows={len(parsed)} Added={added} TotalSoFar={len(all_rows)}\")\n",
    "\n",
    "finally:\n",
    "    driver.quit()\n",
    "\n",
    "df = pd.DataFrame(all_rows).drop_duplicates(subset=[\"review_text\"]).reset_index(drop=True)\n",
    "print(\"Final total after drop_duplicates:\", len(df))\n",
    "\n",
    "df.to_csv(\"imdb_reviews_scraped_2000plus.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\"Saved: imdb_reviews_scraped_2000plus.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "145aa857-3f39-4859-9ee5-7afdf67efddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(\"<html></html>\", \"lxml\")\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "342227a1-f995-4231-8d3a-d4163af74121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Monster Huma H5 v4.1\\.conda\\envs\\lfd_project\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a0cfb5-a795-4687-beda-e7cb8324c2b4",
   "metadata": {},
   "source": [
    "# BALANCED REVIEWS FROM IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e587568e-2ae1-4ffb-b365-ddb9d5e4d792",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "\n",
    "# ====== PROJECT SETTING ======\n",
    "TARGET_PER_CLASS = 700\n",
    "TARGET_TOTAL = TARGET_PER_CLASS * 3\n",
    "\n",
    "LOAD_MORE_PER_MOVIE = 150\n",
    "CLICK_SLEEP = 1.2\n",
    "MIN_WORDS = 12\n",
    "\n",
    "movie_ids = [\n",
    "    \"tt0137523\",  # Fight Club\n",
    "    \"tt0111161\",  # Shawshank\n",
    "    \"tt0068646\",  # The Godfather\n",
    "    \"tt0468569\",  # The Dark Knight\n",
    "    \"tt1375666\",  # Inception\n",
    "    \"tt0816692\",  # Interstellar\n",
    "    \"tt0102926\",  # Silence of the Lambs\n",
    "    \"tt0114369\",  # Se7en\n",
    "    \"tt0172495\",  # Gladiator\n",
    "    \"tt0133093\",  # The Matrix\n",
    "    \"tt0167261\",  # LOTR: Return of the King\n",
    "    \"tt0080684\",  # The Empire Strikes Back\n",
    "    \"tt0076759\",  # Star Wars\n",
    "    \"tt0120737\",  # LOTR: Fellowship of the Ring\n",
    "    \"tt0120586\",  # American History X\n",
    "    \"tt0167404\",  # The Sixth Sense\n",
    "    \"tt0209144\",  # Memento\n",
    "    \"tt0372784\",  # Batman Begins\n",
    "    \"tt0118799\",  # Life Is Beautiful\n",
    "    \"tt0108052\",  # Schindler's List\n",
    "    \"tt0407887\",  # The Departed\n",
    "    \"tt0993846\",  # The Wolf of Wall Street\n",
    "    \"tt1130884\",  # Shutter Island\n",
    "    \"tt0264464\",  # Catch Me If You Can\n",
    "    \"tt1675434\",  # The Intouchables\n",
    "    \"tt4154756\",  # Avengers: Infinity War\n",
    "    \"tt4633694\",  # Spider-Man: Into the Spider-Verse\n",
    "    \"tt2380307\",  # Coco\n",
    "    \"tt0232500\",  # The Room \n",
    "    \"tt12538646\", # 365 Days \n",
    "    \"tt3778644\",  # Ghostbusters\n",
    "    \"tt0293662\",  # The Cat in the Hat \n",
    "    \"tt2450186\",  # The Happening \n",
    "    \"tt0818157\",  # The Incredible Hulk\n",
    "    \"tt0099785\",  # Highlander 2 \n",
    "    \"tt0419706\",  # Transformers \n",
    "    \"tt2109248\",  # Transformers: Age of Extinction \n",
    "    \"tt9243804\",  # Cats (2019)\n",
    "    \"tt1571249\",  # RoboCop (2014)\n",
    "    \"tt1045658\",  # The Love Guru\n",
    "    \"tt0298203\",  # Catwoman\n",
    "    \"tt1600195\",  # Grown Ups 2\n",
    "]\n",
    "\n",
    "\n",
    "def label_from_rating(r):\n",
    "    if r >= 7:\n",
    "        return \"positive\"\n",
    "    elif r <= 4:\n",
    "        return \"negative\"\n",
    "    else:\n",
    "        return \"neutral\"   # 5–6\n",
    "\n",
    "\n",
    "# ====== SELENIUM SETTING ======\n",
    "opts = Options()\n",
    "opts.add_argument(\"--lang=en-US\")\n",
    "opts.add_argument(\"--window-size=1400,900\")\n",
    "opts.add_argument(\"--no-sandbox\")\n",
    "opts.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "prefs = {\"profile.managed_default_content_settings.images\": 2}\n",
    "opts.add_experimental_option(\"prefs\", prefs)\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=opts)\n",
    "wait = WebDriverWait(driver, 25)\n",
    "\n",
    "\n",
    "# ====== GLOBAL VARIABLES ======\n",
    "all_rows = []\n",
    "\n",
    "class_counts = {\n",
    "    \"positive\": 0,\n",
    "    \"neutral\": 0,\n",
    "    \"negative\": 0\n",
    "}\n",
    "\n",
    "\n",
    "# ====== AUXILIARY FUNCTIONS ======\n",
    "def accept_consent_if_present():\n",
    "    xpaths = [\n",
    "        \"//button[contains(., 'Accept')]\",\n",
    "        \"//button[contains(., 'Accept all')]\",\n",
    "        \"//button[contains(., 'I agree')]\",\n",
    "        \"//button[contains(., 'Agree')]\",\n",
    "    ]\n",
    "    for xp in xpaths:\n",
    "        try:\n",
    "            btn = WebDriverWait(driver, 3).until(EC.element_to_be_clickable((By.XPATH, xp)))\n",
    "            btn.click()\n",
    "            time.sleep(1)\n",
    "            return True\n",
    "        except:\n",
    "            pass\n",
    "    return False\n",
    "\n",
    "\n",
    "def click_load_more(max_clicks):\n",
    "    clicks = 0\n",
    "    for _ in range(max_clicks):\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(0.6)\n",
    "        try:\n",
    "            btn = WebDriverWait(driver, 3).until(\n",
    "                EC.element_to_be_clickable((By.CSS_SELECTOR, \"button.ipc-see-more__button\"))\n",
    "            )\n",
    "            driver.execute_script(\"arguments[0].click();\", btn)\n",
    "            clicks += 1\n",
    "            time.sleep(CLICK_SLEEP)\n",
    "        except:\n",
    "            break\n",
    "    return clicks\n",
    "\n",
    "\n",
    "def parse_reviews_from_html(html, movie_id):\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    rows = []\n",
    "\n",
    "    # ---- Old layout ----\n",
    "    cards = soup.select(\"div.review-container\")\n",
    "    if cards:\n",
    "        for c in cards:\n",
    "            text_tag = c.select_one(\"div.text.show-more__control\")\n",
    "            rating_tag = c.select_one(\"span.rating-other-user-rating span\")\n",
    "            if not text_tag or not rating_tag:\n",
    "                continue\n",
    "            review_text = text_tag.get_text(strip=True)\n",
    "            if len(review_text.split()) < MIN_WORDS:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                rating = int(rating_tag.get_text(strip=True))\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            rows.append((review_text, rating, movie_id))\n",
    "        return rows\n",
    "\n",
    "    # ---- New layout ----\n",
    "    articles = soup.select(\"article\")\n",
    "    for a in articles:\n",
    "        block_text = a.get_text(\" \", strip=True)\n",
    "        m = re.search(r\"\\b(\\d{1,2})/10\\b\", block_text)\n",
    "        if not m:\n",
    "            continue\n",
    "        rating = int(m.group(1))\n",
    "\n",
    "        text = None\n",
    "        for sel in [\n",
    "            '[data-testid=\"review-content\"]',\n",
    "            \"div.ipc-html-content-inner-div\",\n",
    "            \"div.text.show-more__control\",\n",
    "        ]:\n",
    "            t = a.select_one(sel)\n",
    "            if t:\n",
    "                text = t.get_text(\" \", strip=True)\n",
    "                break\n",
    "\n",
    "        if not text:\n",
    "            text = block_text\n",
    "\n",
    "        if len(text.split()) < MIN_WORDS:\n",
    "            continue\n",
    "\n",
    "        rows.append((text, rating, movie_id))\n",
    "\n",
    "    return rows\n",
    "\n",
    "\n",
    "# ====== AMIN SCRAPING ======\n",
    "try:\n",
    "    for mid in movie_ids:\n",
    "\n",
    "        if all(class_counts[c] >= TARGET_PER_CLASS for c in class_counts):\n",
    "            break\n",
    "\n",
    "        url = f\"https://www.imdb.com/title/{mid}/reviews\"\n",
    "        driver.get(url)\n",
    "        time.sleep(2.0)\n",
    "        accept_consent_if_present()\n",
    "\n",
    "        try:\n",
    "            wait.until(lambda d: \"ipc-see-more__button\" in d.page_source or \"/10\" in d.page_source)\n",
    "        except:\n",
    "            print(mid, \"Page did not load reviews properly (blocked/consent).\")\n",
    "            continue\n",
    "\n",
    "        clicks = click_load_more(LOAD_MORE_PER_MOVIE)\n",
    "        \n",
    "        html = driver.page_source\n",
    "        parsed = parse_reviews_from_html(html, mid)\n",
    "\n",
    "        added = 0\n",
    "        for review_text, rating, movie_id in parsed:\n",
    "            label = label_from_rating(rating)\n",
    "\n",
    "            if class_counts[label] >= TARGET_PER_CLASS:\n",
    "                continue\n",
    "\n",
    "            all_rows.append({\n",
    "                \"review_text\": review_text,\n",
    "                \"label\": label,\n",
    "                \"rating\": rating,\n",
    "                \"movie_id\": movie_id\n",
    "            })\n",
    "\n",
    "            class_counts[label] += 1\n",
    "            added += 1\n",
    "\n",
    "            if all(class_counts[c] >= TARGET_PER_CLASS for c in class_counts):\n",
    "                break\n",
    "\n",
    "        print(mid, f\"LoadMoreClickes={clicks}\", f\"Added={added}\", f\"Counts={class_counts}\")\n",
    "\n",
    "finally:\n",
    "    driver.quit()\n",
    "\n",
    "\n",
    "# ====== DATAFRAME & CSV ======\n",
    "df = (pd.DataFrame(all_rows).drop_duplicates(subset=[\"review_text\"]).reset_index(drop=True))\n",
    "\n",
    "print(\"\\nFINAL CLASS DISTRIBUTION:\")\n",
    "print(df[\"label\"].value_counts())\n",
    "\n",
    "df.to_csv(\"imdb_reviews_balanced_2100.csv\",index=False,encoding=\"utf-8-sig\")\n",
    "print(\"\\nSaved: imdb_reviews_balanced_2100.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cb8819f-6b03-4ded-aa59-3d56ed7e1f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tt0137523 LoadMore=150 Added=257 Counts={'positive': 206, 'neutral': 30, 'negative': 21}\n",
      "tt0111161 LoadMore=150 Added=188 Counts={'positive': 365, 'neutral': 47, 'negative': 33}\n",
      "tt0068646 LoadMore=150 Added=205 Counts={'positive': 532, 'neutral': 64, 'negative': 54}\n",
      "tt0468569 LoadMore=150 Added=212 Counts={'positive': 700, 'neutral': 90, 'negative': 72}\n",
      "tt1375666 LoadMore=150 Added=35 Counts={'positive': 700, 'neutral': 111, 'negative': 86}\n",
      "tt0816692 LoadMore=150 Added=38 Counts={'positive': 700, 'neutral': 129, 'negative': 106}\n",
      "tt0102926 LoadMore=76 Added=23 Counts={'positive': 700, 'neutral': 146, 'negative': 112}\n",
      "tt0114369 LoadMore=91 Added=36 Counts={'positive': 700, 'neutral': 170, 'negative': 124}\n",
      "tt0172495 LoadMore=132 Added=41 Counts={'positive': 700, 'neutral': 195, 'negative': 140}\n",
      "tt0133093 LoadMore=150 Added=48 Counts={'positive': 700, 'neutral': 221, 'negative': 162}\n",
      "tt0167261 LoadMore=115 Added=46 Counts={'positive': 700, 'neutral': 251, 'negative': 178}\n",
      "tt0080684 LoadMore=63 Added=11 Counts={'positive': 700, 'neutral': 257, 'negative': 183}\n",
      "tt0076759 LoadMore=92 Added=23 Counts={'positive': 700, 'neutral': 274, 'negative': 189}\n",
      "\n",
      "FINAL CLASS DISTRIBUTION:\n",
      "label\n",
      "positive    700\n",
      "neutral     270\n",
      "negative    185\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Saved: imdb_reviews_balanced_2100.csv\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "\n",
    "# ====== PROJE AYARLARI ======\n",
    "NEEDED_NEUTRAL = 430\n",
    "NEEDED_NEGATIVE = 515\n",
    "TARGET_TOTAL = TARGET_PER_CLASS * 3\n",
    "\n",
    "LOAD_MORE_PER_MOVIE = 150\n",
    "CLICK_SLEEP = 1.2\n",
    "MIN_WORDS = 12\n",
    "\n",
    "movie_ids = [\n",
    "    \"tt0137523\",  # Fight Club\n",
    "    \"tt0111161\",  # Shawshank\n",
    "    \"tt0068646\",  # The Godfather\n",
    "    \"tt0468569\",  # The Dark Knight\n",
    "    \"tt1375666\",  # Inception\n",
    "    \"tt0816692\",  # Interstellar\n",
    "    \"tt0102926\",  # Silence of the Lambs\n",
    "    \"tt0114369\",  # Se7en\n",
    "    \"tt0172495\",  # Gladiator\n",
    "    \"tt0133093\",  # The Matrix\n",
    "    \"tt0167261\",  # LOTR: Return of the King\n",
    "    \"tt0080684\",  # The Empire Strikes Back\n",
    "    \"tt0076759\",  # Star Wars\n",
    "    \"tt0120737\",  # LOTR: Fellowship of the Ring\n",
    "    \"tt0120586\",  # American History X\n",
    "    \"tt0167404\",  # The Sixth Sense\n",
    "    \"tt0209144\",  # Memento\n",
    "    \"tt0372784\",  # Batman Begins\n",
    "    \"tt0118799\",  # Life Is Beautiful\n",
    "    \"tt0108052\",  # Schindler's List\n",
    "    \"tt0407887\",  # The Departed\n",
    "    \"tt0993846\",  # The Wolf of Wall Street\n",
    "    \"tt1130884\",  # Shutter Island\n",
    "    \"tt0264464\",  # Catch Me If You Can\n",
    "    \"tt1675434\",  # The Intouchables\n",
    "    \"tt4154756\",  # Avengers: Infinity War\n",
    "    \"tt4633694\",  # Spider-Man: Into the Spider-Verse\n",
    "    \"tt2380307\",  # Coco\n",
    "]\n",
    "\n",
    "\n",
    "def label_from_rating(r):\n",
    "    if r >= 7:\n",
    "        return \"positive\"\n",
    "    elif r <= 4:\n",
    "        return \"negative\"\n",
    "    else:\n",
    "        return \"neutral\"   # 5–6\n",
    "\n",
    "\n",
    "# ====== SELENIUM AYARLARI ======\n",
    "opts = Options()\n",
    "# opts.add_argument(\"--headless=new\")  # Her şey çalışınca açabilirsin\n",
    "opts.add_argument(\"--lang=en-US\")\n",
    "opts.add_argument(\"--window-size=1400,900\")\n",
    "opts.add_argument(\"--no-sandbox\")\n",
    "opts.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "prefs = {\"profile.managed_default_content_settings.images\": 2}\n",
    "opts.add_experimental_option(\"prefs\", prefs)\n",
    "\n",
    "driver = webdriver.Chrome(\n",
    "    service=Service(ChromeDriverManager().install()),\n",
    "    options=opts\n",
    ")\n",
    "\n",
    "wait = WebDriverWait(driver, 25)\n",
    "\n",
    "\n",
    "# ====== GLOBAL DEĞİŞKENLER ======\n",
    "all_rows = []\n",
    "\n",
    "class_counts = {\n",
    "    \"positive\": 0,\n",
    "    \"neutral\": 0,\n",
    "    \"negative\": 0\n",
    "}\n",
    "\n",
    "\n",
    "# ====== YARDIMCI FONKSİYONLAR ======\n",
    "def accept_consent_if_present():\n",
    "    xpaths = [\n",
    "        \"//button[contains(., 'Accept')]\",\n",
    "        \"//button[contains(., 'Accept all')]\",\n",
    "        \"//button[contains(., 'I agree')]\",\n",
    "        \"//button[contains(., 'Agree')]\",\n",
    "    ]\n",
    "    for xp in xpaths:\n",
    "        try:\n",
    "            btn = WebDriverWait(driver, 3).until(\n",
    "                EC.element_to_be_clickable((By.XPATH, xp))\n",
    "            )\n",
    "            btn.click()\n",
    "            time.sleep(1)\n",
    "            return True\n",
    "        except:\n",
    "            pass\n",
    "    return False\n",
    "\n",
    "\n",
    "def click_load_more(max_clicks):\n",
    "    clicks = 0\n",
    "    for _ in range(max_clicks):\n",
    "        driver.execute_script(\n",
    "            \"window.scrollTo(0, document.body.scrollHeight);\"\n",
    "        )\n",
    "        time.sleep(0.6)\n",
    "        try:\n",
    "            btn = WebDriverWait(driver, 3).until(\n",
    "                EC.element_to_be_clickable(\n",
    "                    (By.CSS_SELECTOR, \"button.ipc-see-more__button\")\n",
    "                )\n",
    "            )\n",
    "            driver.execute_script(\"arguments[0].click();\", btn)\n",
    "            clicks += 1\n",
    "            time.sleep(CLICK_SLEEP)\n",
    "        except:\n",
    "            break\n",
    "    return clicks\n",
    "\n",
    "\n",
    "def parse_reviews_from_html(html, movie_id):\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    rows = []\n",
    "\n",
    "    # ---- Eski layout ----\n",
    "    cards = soup.select(\"div.review-container\")\n",
    "    if cards:\n",
    "        for c in cards:\n",
    "            text_tag = c.select_one(\"div.text.show-more__control\")\n",
    "            rating_tag = c.select_one(\n",
    "                \"span.rating-other-user-rating span\"\n",
    "            )\n",
    "            if not text_tag or not rating_tag:\n",
    "                continue\n",
    "\n",
    "            text = text_tag.get_text(strip=True)\n",
    "            if len(text.split()) < MIN_WORDS:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                rating = int(rating_tag.get_text(strip=True))\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            rows.append((text, rating, movie_id))\n",
    "        return rows\n",
    "\n",
    "    # ---- Yeni layout ----\n",
    "    articles = soup.select(\"article\")\n",
    "    for a in articles:\n",
    "        block_text = a.get_text(\" \", strip=True)\n",
    "        m = re.search(r\"\\b(\\d{1,2})/10\\b\", block_text)\n",
    "        if not m:\n",
    "            continue\n",
    "\n",
    "        rating = int(m.group(1))\n",
    "\n",
    "        text = None\n",
    "        for sel in [\n",
    "            '[data-testid=\"review-content\"]',\n",
    "            \"div.ipc-html-content-inner-div\",\n",
    "            \"div.text.show-more__control\",\n",
    "        ]:\n",
    "            t = a.select_one(sel)\n",
    "            if t:\n",
    "                text = t.get_text(\" \", strip=True)\n",
    "                break\n",
    "\n",
    "        if not text:\n",
    "            text = block_text\n",
    "\n",
    "        if len(text.split()) < MIN_WORDS:\n",
    "            continue\n",
    "\n",
    "        rows.append((text, rating, movie_id))\n",
    "\n",
    "    return rows\n",
    "\n",
    "\n",
    "# ====== ANA SCRAPING ======\n",
    "try:\n",
    "    for mid in movie_ids:\n",
    "\n",
    "        if all(class_counts[c] >= TARGET_PER_CLASS for c in class_counts):\n",
    "            break\n",
    "\n",
    "        url = f\"https://www.imdb.com/title/{mid}/reviews\"\n",
    "        driver.get(url)\n",
    "        time.sleep(2)\n",
    "        accept_consent_if_present()\n",
    "\n",
    "        try:\n",
    "            wait.until(\n",
    "                lambda d: \"ipc-see-more__button\" in d.page_source\n",
    "                or \"/10\" in d.page_source\n",
    "            )\n",
    "        except:\n",
    "            print(mid, \"-> Reviews yüklenemedi\")\n",
    "            continue\n",
    "\n",
    "        clicks = click_load_more(LOAD_MORE_PER_MOVIE)\n",
    "        parsed = parse_reviews_from_html(driver.page_source, mid)\n",
    "\n",
    "        added = 0\n",
    "        for review_text, rating, movie_id in parsed:\n",
    "            label = label_from_rating(rating)\n",
    "\n",
    "            if class_counts[label] >= TARGET_PER_CLASS:\n",
    "                continue\n",
    "\n",
    "            all_rows.append({\n",
    "                \"review_text\": review_text,\n",
    "                \"label\": label,\n",
    "                \"rating\": rating,\n",
    "                \"movie_id\": movie_id\n",
    "            })\n",
    "\n",
    "            class_counts[label] += 1\n",
    "            added += 1\n",
    "\n",
    "            if all(class_counts[c] >= TARGET_PER_CLASS for c in class_counts):\n",
    "                break\n",
    "\n",
    "        print(\n",
    "            mid,\n",
    "            f\"LoadMore={clicks}\",\n",
    "            f\"Added={added}\",\n",
    "            f\"Counts={class_counts}\"\n",
    "        )\n",
    "\n",
    "finally:\n",
    "    driver.quit()\n",
    "\n",
    "\n",
    "# ====== DATAFRAME & CSV ======\n",
    "df = (\n",
    "    pd.DataFrame(all_rows)\n",
    "    .drop_duplicates(subset=[\"review_text\"])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(\"\\nFINAL CLASS DISTRIBUTION:\")\n",
    "print(df[\"label\"].value_counts())\n",
    "\n",
    "df.to_csv(\n",
    "    \"imdb_reviews_balanced_2100.csv\",\n",
    "    index=False,\n",
    "    encoding=\"utf-8-sig\"\n",
    ")\n",
    "\n",
    "print(\"\\nSaved: imdb_reviews_balanced_2100.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73c5150b-369a-4584-89bf-c475b902e1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tt0120737 LoadMore=150 Added=51 Counts={'neutral': 35, 'negative': 16}\n",
      "tt0120586 LoadMore=72 Added=21 Counts={'neutral': 51, 'negative': 21}\n",
      "tt0167404 LoadMore=100 Added=26 Counts={'neutral': 66, 'negative': 32}\n",
      "tt0209144 LoadMore=107 Added=44 Counts={'neutral': 93, 'negative': 49}\n",
      "tt0372784 LoadMore=134 Added=61 Counts={'neutral': 131, 'negative': 72}\n",
      "tt0118799 LoadMore=65 Added=10 Counts={'neutral': 137, 'negative': 76}\n",
      "tt0108052 LoadMore=96 Added=15 Counts={'neutral': 145, 'negative': 83}\n",
      "tt0407887 LoadMore=109 Added=32 Counts={'neutral': 164, 'negative': 96}\n",
      "tt0993846 LoadMore=80 Added=30 Counts={'neutral': 182, 'negative': 108}\n",
      "tt1130884 LoadMore=73 Added=21 Counts={'neutral': 195, 'negative': 116}\n",
      "tt0264464 LoadMore=46 Added=19 Counts={'neutral': 207, 'negative': 123}\n",
      "tt1675434 LoadMore=37 Added=7 Counts={'neutral': 211, 'negative': 126}\n",
      "tt4154756 LoadMore=150 Added=50 Counts={'neutral': 234, 'negative': 153}\n",
      "tt4633694 LoadMore=94 Added=23 Counts={'neutral': 251, 'negative': 159}\n",
      "tt2380307 LoadMore=60 Added=15 Counts={'neutral': 262, 'negative': 163}\n",
      "\n",
      "FINAL CLASS DISTRIBUTION:\n",
      "label\n",
      "neutral     259\n",
      "negative    163\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Saved: imdb_extra_neutral_negative.csv\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "\n",
    "# ====== PROJE AYARLARI ======\n",
    "NEEDED_NEUTRAL = 430\n",
    "NEEDED_NEGATIVE = 515\n",
    "\n",
    "LOAD_MORE_PER_MOVIE = 150\n",
    "CLICK_SLEEP = 1.2\n",
    "MIN_WORDS = 12\n",
    "\n",
    "movie_ids = [\n",
    "    \"tt0120737\",  # LOTR: Fellowship of the Ring\n",
    "    \"tt0120586\",  # American History X\n",
    "    \"tt0167404\",  # The Sixth Sense\n",
    "    \"tt0209144\",  # Memento\n",
    "    \"tt0372784\",  # Batman Begins\n",
    "    \"tt0118799\",  # Life Is Beautiful\n",
    "    \"tt0108052\",  # Schindler's List\n",
    "    \"tt0407887\",  # The Departed\n",
    "    \"tt0993846\",  # The Wolf of Wall Street\n",
    "    \"tt1130884\",  # Shutter Island\n",
    "    \"tt0264464\",  # Catch Me If You Can\n",
    "    \"tt1675434\",  # The Intouchables\n",
    "    \"tt4154756\",  # Avengers: Infinity War\n",
    "    \"tt4633694\",  # Spider-Man: Into the Spider-Verse\n",
    "    \"tt2380307\",  # Coco\n",
    "    \"tt0232500\",  # The Room \n",
    "    \"tt12538646\", # 365 Days \n",
    "    \"tt3778644\",  # Ghostbusters\n",
    "    \"tt0293662\",  # The Cat in the Hat \n",
    "    \"tt2450186\",  # The Happening \n",
    "    \"tt0818157\",  # The Incredible Hulk\n",
    "    \"tt0099785\",  # Highlander 2 \n",
    "    \"tt0419706\",  # Transformers \n",
    "    \"tt2109248\",  # Transformers: Age of Extinction \n",
    "    \"tt9243804\",  # Cats (2019)\n",
    "]\n",
    "\n",
    "\n",
    "def label_from_rating(r):\n",
    "    if 5 <= r <= 6:\n",
    "        return \"neutral\"\n",
    "    elif r <= 4:\n",
    "        return \"negative\"\n",
    "    else:\n",
    "        return \"positive\"\n",
    "\n",
    "\n",
    "# ====== SELENIUM AYARLARI ======\n",
    "opts = Options()\n",
    "# opts.add_argument(\"--headless=new\")\n",
    "opts.add_argument(\"--lang=en-US\")\n",
    "opts.add_argument(\"--window-size=1400,900\")\n",
    "opts.add_argument(\"--no-sandbox\")\n",
    "opts.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "prefs = {\"profile.managed_default_content_settings.images\": 2}\n",
    "opts.add_experimental_option(\"prefs\", prefs)\n",
    "\n",
    "driver = webdriver.Chrome(\n",
    "    service=Service(ChromeDriverManager().install()),\n",
    "    options=opts\n",
    ")\n",
    "\n",
    "wait = WebDriverWait(driver, 25)\n",
    "\n",
    "\n",
    "# ====== GLOBAL ======\n",
    "all_rows = []\n",
    "class_counts = {\n",
    "    \"neutral\": 0,\n",
    "    \"negative\": 0\n",
    "}\n",
    "\n",
    "\n",
    "# ====== YARDIMCI FONKSİYONLAR ======\n",
    "def accept_consent_if_present():\n",
    "    xpaths = [\n",
    "        \"//button[contains(., 'Accept')]\",\n",
    "        \"//button[contains(., 'Accept all')]\",\n",
    "        \"//button[contains(., 'I agree')]\",\n",
    "        \"//button[contains(., 'Agree')]\",\n",
    "    ]\n",
    "    for xp in xpaths:\n",
    "        try:\n",
    "            btn = WebDriverWait(driver, 3).until(\n",
    "                EC.element_to_be_clickable((By.XPATH, xp))\n",
    "            )\n",
    "            btn.click()\n",
    "            time.sleep(1)\n",
    "            return True\n",
    "        except:\n",
    "            pass\n",
    "    return False\n",
    "\n",
    "\n",
    "def click_load_more(max_clicks):\n",
    "    clicks = 0\n",
    "    for _ in range(max_clicks):\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(0.6)\n",
    "        try:\n",
    "            btn = WebDriverWait(driver, 3).until(\n",
    "                EC.element_to_be_clickable(\n",
    "                    (By.CSS_SELECTOR, \"button.ipc-see-more__button\")\n",
    "                )\n",
    "            )\n",
    "            driver.execute_script(\"arguments[0].click();\", btn)\n",
    "            clicks += 1\n",
    "            time.sleep(CLICK_SLEEP)\n",
    "        except:\n",
    "            break\n",
    "    return clicks\n",
    "\n",
    "\n",
    "def parse_reviews_from_html(html, movie_id):\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    rows = []\n",
    "\n",
    "    # ---- Eski layout ----\n",
    "    cards = soup.select(\"div.review-container\")\n",
    "    if cards:\n",
    "        for c in cards:\n",
    "            text_tag = c.select_one(\"div.text.show-more__control\")\n",
    "            rating_tag = c.select_one(\"span.rating-other-user-rating span\")\n",
    "            if not text_tag or not rating_tag:\n",
    "                continue\n",
    "\n",
    "            text = text_tag.get_text(strip=True)\n",
    "            if len(text.split()) < MIN_WORDS:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                rating = int(rating_tag.get_text(strip=True))\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            rows.append((text, rating, movie_id))\n",
    "        return rows\n",
    "\n",
    "    # ---- Yeni layout ----\n",
    "    articles = soup.select(\"article\")\n",
    "    for a in articles:\n",
    "        block_text = a.get_text(\" \", strip=True)\n",
    "        m = re.search(r\"\\b(\\d{1,2})/10\\b\", block_text)\n",
    "        if not m:\n",
    "            continue\n",
    "        rating = int(m.group(1))\n",
    "\n",
    "        text = None\n",
    "        for sel in [\n",
    "            '[data-testid=\"review-content\"]',\n",
    "            \"div.ipc-html-content-inner-div\",\n",
    "            \"div.text.show-more__control\",\n",
    "        ]:\n",
    "            t = a.select_one(sel)\n",
    "            if t:\n",
    "                text = t.get_text(\" \", strip=True)\n",
    "                break\n",
    "\n",
    "        if not text:\n",
    "            text = block_text\n",
    "\n",
    "        if len(text.split()) < MIN_WORDS:\n",
    "            continue\n",
    "\n",
    "        rows.append((text, rating, movie_id))\n",
    "\n",
    "    return rows\n",
    "\n",
    "\n",
    "# ====== ANA SCRAPING ======\n",
    "try:\n",
    "    for mid in movie_ids:\n",
    "\n",
    "        # hedeflere ulaştıysak çık\n",
    "        if class_counts[\"neutral\"] >= NEEDED_NEUTRAL and class_counts[\"negative\"] >= NEEDED_NEGATIVE:\n",
    "            break\n",
    "\n",
    "        url = f\"https://www.imdb.com/title/{mid}/reviews\"\n",
    "        driver.get(url)\n",
    "        time.sleep(2)\n",
    "        accept_consent_if_present()\n",
    "\n",
    "        try:\n",
    "            wait.until(lambda d: \"ipc-see-more__button\" in d.page_source or \"/10\" in d.page_source)\n",
    "        except:\n",
    "            print(mid, \"-> Reviews yüklenemedi\")\n",
    "            continue\n",
    "\n",
    "        clicks = click_load_more(LOAD_MORE_PER_MOVIE)\n",
    "        parsed = parse_reviews_from_html(driver.page_source, mid)\n",
    "\n",
    "        added = 0\n",
    "        for review_text, rating, movie_id in parsed:\n",
    "            label = label_from_rating(rating)\n",
    "\n",
    "            if label == \"neutral\" and class_counts[\"neutral\"] < NEEDED_NEUTRAL:\n",
    "                pass\n",
    "            elif label == \"negative\" and class_counts[\"negative\"] < NEEDED_NEGATIVE:\n",
    "                pass\n",
    "            else:\n",
    "                continue  # positive'ları veya fazlaları alma\n",
    "\n",
    "            all_rows.append({\n",
    "                \"review_text\": review_text,\n",
    "                \"label\": label,\n",
    "                \"rating\": rating,\n",
    "                \"movie_id\": movie_id\n",
    "            })\n",
    "            class_counts[label] += 1\n",
    "            added += 1\n",
    "\n",
    "            if class_counts[\"neutral\"] >= NEEDED_NEUTRAL and class_counts[\"negative\"] >= NEEDED_NEGATIVE:\n",
    "                break\n",
    "\n",
    "        print(\n",
    "            mid,\n",
    "            f\"LoadMore={clicks}\",\n",
    "            f\"Added={added}\",\n",
    "            f\"Counts={class_counts}\"\n",
    "        )\n",
    "\n",
    "finally:\n",
    "    driver.quit()\n",
    "\n",
    "\n",
    "# ====== DATAFRAME & CSV ======\n",
    "df = (\n",
    "    pd.DataFrame(all_rows)\n",
    "    .drop_duplicates(subset=[\"review_text\"])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(\"\\nFINAL CLASS DISTRIBUTION:\")\n",
    "print(df[\"label\"].value_counts())\n",
    "\n",
    "df.to_csv(\n",
    "    \"imdb_extra_neutral_negative.csv\",\n",
    "    index=False,\n",
    "    encoding=\"utf-8-sig\"\n",
    ")\n",
    "\n",
    "print(\"\\nSaved: imdb_extra_neutral_negative.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "072c6345-65d5-4cfb-bcc6-955ce76a04b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tt1571249 LoadMore=4 Added=1 Counts={'neutral': 0, 'negative': 1}\n",
      "\n",
      "FINAL CLASS DISTRIBUTION:\n",
      "label\n",
      "negative    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Saved: imdb_extra_neutral_negative.csv\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "\n",
    "# ====== PROJE AYARLARI ======\n",
    "NEEDED_NEUTRAL = 0\n",
    "NEEDED_NEGATIVE = 1\n",
    "\n",
    "LOAD_MORE_PER_MOVIE = 150\n",
    "CLICK_SLEEP = 1.2\n",
    "MIN_WORDS = 12\n",
    "\n",
    "movie_ids = [\n",
    "    \"tt1571249\",   # RoboCop (2014)\n",
    "    \"tt1045658\",   # The Love Guru\n",
    "    \"tt0298203\",   # Catwoman\n",
    "    \"tt1600195\",   # Grown Ups 2\n",
    "]\n",
    "\n",
    "\n",
    "def label_from_rating(r):\n",
    "    if 5 <= r <= 6:\n",
    "        return \"neutral\"\n",
    "    elif r <= 4:\n",
    "        return \"negative\"\n",
    "    else:\n",
    "        return \"positive\"\n",
    "\n",
    "\n",
    "# ====== SELENIUM AYARLARI ======\n",
    "opts = Options()\n",
    "# opts.add_argument(\"--headless=new\")\n",
    "opts.add_argument(\"--lang=en-US\")\n",
    "opts.add_argument(\"--window-size=1400,900\")\n",
    "opts.add_argument(\"--no-sandbox\")\n",
    "opts.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "prefs = {\"profile.managed_default_content_settings.images\": 2}\n",
    "opts.add_experimental_option(\"prefs\", prefs)\n",
    "\n",
    "driver = webdriver.Chrome(\n",
    "    service=Service(ChromeDriverManager().install()),\n",
    "    options=opts\n",
    ")\n",
    "\n",
    "wait = WebDriverWait(driver, 25)\n",
    "\n",
    "\n",
    "# ====== GLOBAL ======\n",
    "all_rows = []\n",
    "class_counts = {\n",
    "    \"neutral\": 0,\n",
    "    \"negative\": 0\n",
    "}\n",
    "\n",
    "\n",
    "# ====== YARDIMCI FONKSİYONLAR ======\n",
    "def accept_consent_if_present():\n",
    "    xpaths = [\n",
    "        \"//button[contains(., 'Accept')]\",\n",
    "        \"//button[contains(., 'Accept all')]\",\n",
    "        \"//button[contains(., 'I agree')]\",\n",
    "        \"//button[contains(., 'Agree')]\",\n",
    "    ]\n",
    "    for xp in xpaths:\n",
    "        try:\n",
    "            btn = WebDriverWait(driver, 3).until(\n",
    "                EC.element_to_be_clickable((By.XPATH, xp))\n",
    "            )\n",
    "            btn.click()\n",
    "            time.sleep(1)\n",
    "            return True\n",
    "        except:\n",
    "            pass\n",
    "    return False\n",
    "\n",
    "\n",
    "def click_load_more(max_clicks):\n",
    "    clicks = 0\n",
    "    for _ in range(max_clicks):\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(0.6)\n",
    "        try:\n",
    "            btn = WebDriverWait(driver, 3).until(\n",
    "                EC.element_to_be_clickable(\n",
    "                    (By.CSS_SELECTOR, \"button.ipc-see-more__button\")\n",
    "                )\n",
    "            )\n",
    "            driver.execute_script(\"arguments[0].click();\", btn)\n",
    "            clicks += 1\n",
    "            time.sleep(CLICK_SLEEP)\n",
    "        except:\n",
    "            break\n",
    "    return clicks\n",
    "\n",
    "\n",
    "def parse_reviews_from_html(html, movie_id):\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    rows = []\n",
    "\n",
    "    # ---- Eski layout ----\n",
    "    cards = soup.select(\"div.review-container\")\n",
    "    if cards:\n",
    "        for c in cards:\n",
    "            text_tag = c.select_one(\"div.text.show-more__control\")\n",
    "            rating_tag = c.select_one(\"span.rating-other-user-rating span\")\n",
    "            if not text_tag or not rating_tag:\n",
    "                continue\n",
    "\n",
    "            text = text_tag.get_text(strip=True)\n",
    "            if len(text.split()) < MIN_WORDS:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                rating = int(rating_tag.get_text(strip=True))\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            rows.append((text, rating, movie_id))\n",
    "        return rows\n",
    "\n",
    "    # ---- Yeni layout ----\n",
    "    articles = soup.select(\"article\")\n",
    "    for a in articles:\n",
    "        block_text = a.get_text(\" \", strip=True)\n",
    "        m = re.search(r\"\\b(\\d{1,2})/10\\b\", block_text)\n",
    "        if not m:\n",
    "            continue\n",
    "        rating = int(m.group(1))\n",
    "\n",
    "        text = None\n",
    "        for sel in [\n",
    "            '[data-testid=\"review-content\"]',\n",
    "            \"div.ipc-html-content-inner-div\",\n",
    "            \"div.text.show-more__control\",\n",
    "        ]:\n",
    "            t = a.select_one(sel)\n",
    "            if t:\n",
    "                text = t.get_text(\" \", strip=True)\n",
    "                break\n",
    "\n",
    "        if not text:\n",
    "            text = block_text\n",
    "\n",
    "        if len(text.split()) < MIN_WORDS:\n",
    "            continue\n",
    "\n",
    "        rows.append((text, rating, movie_id))\n",
    "\n",
    "    return rows\n",
    "\n",
    "\n",
    "# ====== ANA SCRAPING ======\n",
    "try:\n",
    "    for mid in movie_ids:\n",
    "\n",
    "        # hedeflere ulaştıysak çık\n",
    "        if class_counts[\"neutral\"] >= NEEDED_NEUTRAL and class_counts[\"negative\"] >= NEEDED_NEGATIVE:\n",
    "            break\n",
    "\n",
    "        url = f\"https://www.imdb.com/title/{mid}/reviews\"\n",
    "        driver.get(url)\n",
    "        time.sleep(2)\n",
    "        accept_consent_if_present()\n",
    "\n",
    "        try:\n",
    "            wait.until(lambda d: \"ipc-see-more__button\" in d.page_source or \"/10\" in d.page_source)\n",
    "        except:\n",
    "            print(mid, \"-> Reviews yüklenemedi\")\n",
    "            continue\n",
    "\n",
    "        clicks = click_load_more(LOAD_MORE_PER_MOVIE)\n",
    "        parsed = parse_reviews_from_html(driver.page_source, mid)\n",
    "\n",
    "        added = 0\n",
    "        for review_text, rating, movie_id in parsed:\n",
    "            label = label_from_rating(rating)\n",
    "\n",
    "            if label == \"neutral\" and class_counts[\"neutral\"] < NEEDED_NEUTRAL:\n",
    "                pass\n",
    "            elif label == \"negative\" and class_counts[\"negative\"] < NEEDED_NEGATIVE:\n",
    "                pass\n",
    "            else:\n",
    "                continue  # positive'ları veya fazlaları alma\n",
    "\n",
    "            all_rows.append({\n",
    "                \"review_text\": review_text,\n",
    "                \"label\": label,\n",
    "                \"rating\": rating,\n",
    "                \"movie_id\": movie_id\n",
    "            })\n",
    "            class_counts[label] += 1\n",
    "            added += 1\n",
    "\n",
    "            if class_counts[\"neutral\"] >= NEEDED_NEUTRAL and class_counts[\"negative\"] >= NEEDED_NEGATIVE:\n",
    "                break\n",
    "\n",
    "        print(\n",
    "            mid,\n",
    "            f\"LoadMore={clicks}\",\n",
    "            f\"Added={added}\",\n",
    "            f\"Counts={class_counts}\"\n",
    "        )\n",
    "\n",
    "finally:\n",
    "    driver.quit()\n",
    "\n",
    "\n",
    "# ====== DATAFRAME & CSV ======\n",
    "df = (\n",
    "    pd.DataFrame(all_rows)\n",
    "    .drop_duplicates(subset=[\"review_text\"])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(\"\\nFINAL CLASS DISTRIBUTION:\")\n",
    "print(df[\"label\"].value_counts())\n",
    "\n",
    "df.to_csv(\n",
    "    \"imdb_extra_neutral_negative.csv\",\n",
    "    index=False,\n",
    "    encoding=\"utf-8-sig\"\n",
    ")\n",
    "\n",
    "print(\"\\nSaved: imdb_extra_neutral_negative.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f005c93-441c-4272-8bf2-31f27c4de2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(\"balanced_imdb_comments.csv\")\n",
    "df2 = pd.read_csv(\"imdb_extra_neutral_negative.csv\")\n",
    "\n",
    "merged = pd.concat([df1, df2], ignore_index=True).drop_duplicates(subset=[\"review_text\"])\n",
    "\n",
    "merged.to_csv(\"balanced_imdb_comments.csv\", index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9d4b8a-760c-47f0-88aa-ce790333bba2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c76b684-db46-4da2-aa27-c602e4a800e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"balanced_imdb_comments.csv\")\n",
    "\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "df.to_csv(\"balanced_imdb_comments.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe977e19-1df9-42af-8ce4-803411355bb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (lfd_project)",
   "language": "python",
   "name": "lfd_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
